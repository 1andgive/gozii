                                                                                 N/A% (0 of 17640) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--                                                                                 N/A% (0 of 17640) |                        | Elapsed Time: 0:00:06 ETA:  --:--:--/home/user/anaconda3/envs/sj_torch1.0/lib/python3.6/site-packages/torch/nn/modules/rnn.py:179: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.dropout, self.training, self.bidirectional, self.batch_first)
                                                                                   0% (1 of 17640) |                | Elapsed Time: 0:00:18 ETA:  2 days, 11:29:05                                                                                   0% (2 of 17640) |                 | Elapsed Time: 0:00:25 ETA:  1 day, 11:32:55                                                                                   0% (3 of 17640) |                 | Elapsed Time: 0:00:32 ETA:  1 day, 11:11:25Traceback (most recent call last):
  File "train_UNION_BUTD.py", line 183, in <module>
    main(args)
  File "train_UNION_BUTD.py", line 141, in main
    loss.backward()
  File "/home/user/anaconda3/envs/sj_torch1.0/lib/python3.6/site-packages/torch/tensor.py", line 102, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/user/anaconda3/envs/sj_torch1.0/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 11.91 GiB total capacity; 3.69 GiB already allocated; 2.02 GiB free; 5.56 GiB cached)
                                                                                 